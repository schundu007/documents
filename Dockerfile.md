# üê≥ Docker Complete Guide

> From Fundamentals to Production-Ready Dockerfiles

A comprehensive guide covering Docker concepts, commands cheatsheet, use cases, and production-grade Dockerfiles for Node.js, Java, .NET, Python, and Frontend applications.

---

## üìë Table of Contents

- [1. What is Docker?](#1-what-is-docker)
- [2. Docker Commands Cheatsheet](#2-docker-commands-cheatsheet)
- [3. Docker Use Cases](#3-docker-use-cases)
- [4. Dockerfile Instructions Reference](#4-dockerfile-instructions-reference)
- [5. Production-Ready Dockerfiles](#5-production-ready-dockerfiles)
- [6. Advanced Dockerfile Patterns](#6-advanced-dockerfile-patterns)
- [7. Best Practices Summary](#7-best-practices-summary)

---

## 1. What is Docker?

Docker is an open-source containerization platform that enables developers to package applications along with all their dependencies into standardized units called **containers**. These containers are lightweight, portable, and ensure consistent behavior across different environments‚Äîfrom development laptops to production servers.

### 1.1 Core Concepts

| Concept | Description |
|---------|-------------|
| **Container** | A lightweight, standalone executable package that includes everything needed to run an application: code, runtime, system tools, libraries, and settings. |
| **Image** | A read-only template containing instructions for creating a container. Images are built in layers, where each layer represents a Dockerfile instruction. |
| **Dockerfile** | A text file containing sequential instructions to build a Docker image. |
| **Registry** | A storage and distribution system for Docker images (e.g., Docker Hub, AWS ECR, Azure ACR). |
| **Volume** | A mechanism for persisting data generated by containers. |

### 1.2 Docker Architecture

Docker uses a client-server architecture. The Docker client communicates with the Docker daemon (dockerd), which builds, runs, and manages containers.

| Component | Description |
|-----------|-------------|
| **Docker Client** | CLI tool (`docker`) that users interact with. Sends commands to the daemon. |
| **Docker Daemon** | Background service (`dockerd`) that manages images, containers, networks, and volumes. |
| **containerd** | Industry-standard container runtime that manages container lifecycle. |
| **runc** | Low-level OCI-compliant runtime that creates and runs containers. |

---

## 2. Docker Commands Cheatsheet

### 2.1 Image Management

```bash
# Build image from Dockerfile in current directory
docker build -t <name:tag> .

# List all local images
docker images

# Download image from registry
docker pull <image:tag>

# Upload image to registry
docker push <image:tag>

# Remove an image
docker rmi <image>

# Create a tag pointing to source image
docker tag <source> <target>

# Show image layer history
docker history <image>

# Remove unused images
docker image prune
```

### 2.2 Container Lifecycle

```bash
# Create and start a container
docker run <image>

# Run container in detached mode
docker run -d <image>

# Run with interactive terminal
docker run -it <image> /bin/sh

# Map host port 8080 to container port 80
docker run -p 8080:80 <image>

# Mount host directory as volume
docker run -v /host/path:/container/path <image>

# Set environment variable
docker run -e VAR=value <image>

# Assign name to container
docker run --name myapp <image>

# Remove container when it exits
docker run --rm <image>

# List running containers
docker ps

# List all containers (including stopped)
docker ps -a

# Gracefully stop a container
docker stop <container>

# Start a stopped container
docker start <container>

# Restart a container
docker restart <container>

# Remove a stopped container
docker rm <container>

# Force remove running container
docker rm -f <container>
```

### 2.3 Container Inspection & Debugging

```bash
# View container logs
docker logs <container>

# Follow log output (tail)
docker logs -f <container>

# Open shell inside running container
docker exec -it <container> /bin/sh

# View detailed container information
docker inspect <container>

# Live resource usage statistics
docker stats

# Display running processes in container
docker top <container>

# Copy files to/from container
docker cp <source> <container>:<dest>
```

### 2.4 Network & Volume Commands

```bash
# List all networks
docker network ls

# Create a new network
docker network create <name>

# Connect container to network
docker network connect <network> <container>

# List all volumes
docker volume ls

# Create a named volume
docker volume create <name>

# Remove unused volumes
docker volume prune
```

### 2.5 Cleanup Commands

```bash
# Remove unused data (containers, networks, images)
docker system prune

# Remove all unused data including volumes
docker system prune -a --volumes

# Remove all stopped containers
docker container prune

# Show Docker disk usage
docker system df
```

---

## 3. Docker Use Cases

### 3.1 Development & Testing

- **Consistent Development Environments**: Eliminates "works on my machine" problems by ensuring all developers use identical environments.
- **Isolated Testing**: Run integration tests with real databases, message queues, and other services in isolated containers.
- **Multi-Version Testing**: Test applications against multiple versions of dependencies by simply changing the base image tag.

### 3.2 CI/CD Pipelines

- **Build Reproducibility**: Dockerfile instructions create deterministic builds regardless of when or where it's built.
- **Pipeline Stages**: Use multi-stage builds to create separate build and runtime images.
- **Parallel Testing**: Spin up multiple container instances to run tests in parallel.

### 3.3 Microservices Architecture

- **Service Isolation**: Each microservice runs in its own container with dedicated resources.
- **Independent Scaling**: Scale individual services based on demand.
- **Service Discovery**: Docker networks enable container-to-container communication using service names.

### 3.4 Cloud-Native Deployment

- **Kubernetes Orchestration**: Docker images are the deployment unit for Kubernetes.
- **Serverless Containers**: Deploy on AWS Fargate, Azure Container Instances, or Google Cloud Run.
- **Hybrid Cloud**: Same container images run across AWS, Azure, GCP, or on-premises.

---

## 4. Dockerfile Instructions Reference

### 4.1 Base Image & Metadata

#### FROM

The `FROM` instruction initializes a new build stage and sets the base image for subsequent instructions. Every valid Dockerfile must begin with `FROM` (with the exception of `ARG`, which may precede it).

```dockerfile
FROM node:20-alpine
FROM python:3.12-slim AS builder
FROM mcr.microsoft.com/dotnet/sdk:8.0
```

> **Best Practice**: Use specific version tags instead of `latest`. Prefer slim/alpine variants for smaller images.

#### LABEL

Labels add metadata to images as key-value pairs, invaluable for image management and documentation.

```dockerfile
LABEL org.opencontainers.image.source="https://github.com/org/repo"
LABEL org.opencontainers.image.description="Production API Service"
LABEL maintainer="team@company.com"
```

### 4.2 Environment & Arguments

#### ARG

Build-time arguments allow parameterization of the build process without persisting values in the final image.

```dockerfile
ARG NODE_VERSION=20
ARG BUILD_DATE
FROM node:${NODE_VERSION}-alpine
```

> ‚ö†Ô∏è **Security Warning**: Never use `ARG` for secrets‚Äîvalues appear in image history.

#### ENV

Environment variables set with `ENV` persist in the running container, available during build and runtime.

```dockerfile
ENV NODE_ENV=production
ENV PORT=3000 LOG_LEVEL=info
```

### 4.3 File Operations

#### WORKDIR

Establishes the working directory for all subsequent instructions. Creates the directory if it doesn't exist.

```dockerfile
WORKDIR /app
WORKDIR /home/appuser/src
```

> **Best Practice**: Always use `WORKDIR` instead of `RUN cd` commands.

#### COPY

Transfers files from the build context into the image filesystem. Supports wildcards and preserves permissions.

```dockerfile
COPY package*.json ./
COPY --chown=node:node . .
COPY --from=builder /app/dist ./dist
```

#### ADD

Similar to `COPY` but with extra features: auto-extracts tar archives and can fetch remote URLs.

```dockerfile
ADD app.tar.gz /app/
ADD https://example.com/file.txt /data/
```

> **Best Practice**: Prefer `COPY` unless you specifically need `ADD`'s extraction capability.

### 4.4 Execution Instructions

#### RUN

Executes commands during the image build process. Each instruction creates a new layer.

```dockerfile
# Shell form
RUN npm ci --only=production

# Combining commands to reduce layers
RUN apt-get update && \
    apt-get install -y curl && \
    rm -rf /var/lib/apt/lists/*

# Exec form
RUN ["executable", "param1", "param2"]
```

#### CMD

Specifies the default command executed when a container starts. Can be overridden at runtime.

```dockerfile
CMD ["node", "server.js"]
CMD ["python", "-m", "flask", "run"]
```

#### ENTRYPOINT

Configures the container to run as an executable. Arguments append to `ENTRYPOINT` rather than replacing it.

```dockerfile
ENTRYPOINT ["docker-entrypoint.sh"]
ENTRYPOINT ["java", "-jar", "app.jar"]
```

> **Best Practice**: Use `ENTRYPOINT` for the main executable, `CMD` for default arguments.

### 4.5 Network & Security

#### EXPOSE

Documents the ports the container listens on. Does not actually publish ports.

```dockerfile
EXPOSE 3000
EXPOSE 80 443
EXPOSE 8080/tcp 8081/udp
```

#### USER

Sets the user (and optionally group) for subsequent instructions and container runtime.

```dockerfile
# Create and switch to non-root user
RUN addgroup --system app && adduser --system --ingroup app app
USER app

# Or use numeric UID for Kubernetes compatibility
USER 1001:1001
```

> ‚ö†Ô∏è **Security**: Never run production containers as root.

#### HEALTHCHECK

Defines a command to check if the container is healthy.

```dockerfile
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1
```

#### VOLUME

Creates a mount point for externally mounted volumes.

```dockerfile
VOLUME /data
VOLUME ["/var/log", "/var/data"]
```

---

## 5. Production-Ready Dockerfiles

### 5.1 Node.js Application

```dockerfile
FROM node:20-alpine AS deps
WORKDIR /app
COPY package.json package-lock.json ./
RUN npm ci

FROM node:20-alpine AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .
RUN npm run build && npm prune --production

FROM node:20-alpine AS production
LABEL org.opencontainers.image.title="Node.js API"
ENV NODE_ENV=production PORT=3000
RUN apk add --no-cache dumb-init
WORKDIR /app
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/package.json ./
USER node
EXPOSE 3000
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD node -e "require('http').get('http://localhost:3000/health')"
CMD ["dumb-init", "node", "dist/server.js"]
```

#### Understanding the Node.js Dockerfile

This Dockerfile employs a **three-stage build strategy** that separates concerns for maximum efficiency:

1. **Stage 1 (deps)**: Focuses exclusively on dependency installation. By copying only `package.json` and `package-lock.json` before running `npm ci`, we leverage Docker's layer caching‚Äîif these files haven't changed, Docker reuses the cached `node_modules` layer.

2. **Stage 2 (builder)**: Handles the build process. It imports `node_modules` from the deps stage, copies source code, and executes the build. After building, `npm prune --production` removes development dependencies.

3. **Stage 3 (production)**: Starts fresh with Alpine base, installing only `dumb-init`‚Äîa minimal init system that properly handles SIGTERM signals. Node.js applications running as PID 1 don't handle signals correctly by default, which can prevent graceful shutdown.

Security considerations: The container runs as the built-in `node` user rather than root, and the `HEALTHCHECK` enables orchestrators to detect and restart unhealthy containers.

---

### 5.2 Java / Spring Boot Application

```dockerfile
FROM eclipse-temurin:21-jdk AS builder
RUN apt-get update && apt-get install -y maven && rm -rf /var/lib/apt/lists/*
WORKDIR /build
COPY pom.xml .
RUN mvn dependency:go-offline -B
COPY src ./src
RUN mvn package -DskipTests -B
RUN java -Djarmode=layertools -jar target/*.jar extract

FROM eclipse-temurin:21-jre-alpine AS production
LABEL org.opencontainers.image.title="Spring Boot API"
ENV JAVA_OPTS="-XX:MaxRAMPercentage=75.0 -XX:+UseContainerSupport \
    -XX:+UseG1GC -XX:+ExitOnOutOfMemoryError"
RUN addgroup --system javauser && adduser --system --ingroup javauser javauser
WORKDIR /app
COPY --from=builder /build/dependencies/ ./
COPY --from=builder /build/spring-boot-loader/ ./
COPY --from=builder /build/snapshot-dependencies/ ./
COPY --from=builder /build/application/ ./
RUN chown -R javauser:javauser /app
USER javauser
EXPOSE 8080
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD wget -q --spider http://localhost:8080/actuator/health || exit 1
ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS org.springframework.boot.loader.JarLauncher"]
```

#### Understanding the Java Dockerfile

Java applications present unique containerization challenges around JVM memory management and image size:

**Spring Boot Layered JARs**: The command `java -Djarmode=layertools` extracts the fat JAR into four directories: `dependencies`, `spring-boot-loader`, `snapshot-dependencies`, and `application`. By copying these layers in order of change frequency (dependencies change rarely, application code changes often), we maximize Docker layer caching.

**JVM Container Settings**:
- `MaxRAMPercentage=75.0`: Use 75% of container's memory limit instead of host's total memory
- `UseContainerSupport`: Enable automatic container detection
- `UseG1GC`: Select garbage collector optimized for low latency
- `ExitOnOutOfMemoryError`: Ensure clean container death on OOM, allowing orchestrator restarts

The production stage uses **JRE Alpine** rather than JDK, dramatically reducing image size.

---

### 5.3 .NET / ASP.NET Core Application

```dockerfile
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS restore
WORKDIR /src
COPY *.sln .
COPY src/**/*.csproj ./src/
RUN dotnet restore

FROM restore AS build
COPY . .
RUN dotnet build -c Release --no-restore
RUN dotnet publish src/Api/Api.csproj -c Release -o /app/publish --no-build

FROM mcr.microsoft.com/dotnet/aspnet:8.0-alpine AS production
LABEL org.opencontainers.image.title="ASP.NET Core API"
ENV ASPNETCORE_URLS=http://+:8080
ENV ASPNETCORE_ENVIRONMENT=Production
ENV DOTNET_EnableDiagnostics=0
RUN addgroup --system appgroup && adduser --system --ingroup appgroup appuser
WORKDIR /app
COPY --from=build --chown=appuser:appgroup /app/publish .
USER appuser
EXPOSE 8080
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD wget -q --spider http://localhost:8080/health || exit 1
ENTRYPOINT ["dotnet", "Api.dll"]
```

#### Understanding the .NET Dockerfile

Microsoft's official .NET images follow a clear separation between SDK (for building) and runtime (for execution):

1. **Restore Stage**: Copies only project files and solution files, then runs `dotnet restore` to download NuGet packages‚Äîbenefiting greatly from layer caching.

2. **Build Stage**: Inherits from restore (note `FROM restore AS build`), bringing along restored packages. Uses `--no-restore` and `--no-build` flags to prevent redundant work.

3. **Production Stage**: Uses Alpine variant of ASP.NET runtime for minimal footprint. Environment variables configure ASP.NET Core for containerization:
   - `ASPNETCORE_URLS`: Binds to all interfaces on port 8080
   - `DOTNET_EnableDiagnostics=0`: Disables diagnostic features that could pose security risks

---

### 5.4 Python / FastAPI Application

```dockerfile
FROM python:3.12-slim AS builder
ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential libpq-dev && rm -rf /var/lib/apt/lists/*
WORKDIR /app
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

FROM python:3.12-slim AS production
LABEL org.opencontainers.image.title="FastAPI Application"
ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
ENV PATH="/opt/venv/bin:$PATH"
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq5 curl && rm -rf /var/lib/apt/lists/*
RUN groupadd --system app && useradd --system --gid app app
WORKDIR /app
COPY --from=builder /opt/venv /opt/venv
COPY --chown=app:app . .
USER app
EXPOSE 8000
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1
CMD ["gunicorn", "main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "-b", "0.0.0.0:8000"]
```

#### Understanding the Python Dockerfile

Python containerization benefits significantly from **virtual environment isolation**, even within containers:

**Environment Variables**:
- `PYTHONDONTWRITEBYTECODE=1`: Prevents Python from writing `.pyc` files (unnecessary in containers)
- `PYTHONUNBUFFERED=1`: Ensures print statements and logging appear immediately without buffering

**Build vs Runtime Dependencies**: The builder stage installs `build-essential` and `libpq-dev` to compile native extensions. The production stage installs only the runtime library `libpq5`.

**Production Server**: Gunicorn with Uvicorn workers provides process management and ASGI protocol handling. Four workers deliver production-grade performance with proper process lifecycle management.

---

### 5.5 React / Frontend Application

```dockerfile
FROM node:20-alpine AS deps
WORKDIR /app
COPY package.json package-lock.json ./
RUN npm ci

FROM node:20-alpine AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .
ARG REACT_APP_API_URL
ENV REACT_APP_API_URL=$REACT_APP_API_URL
RUN npm run build

FROM nginxinc/nginx-unprivileged:1.25-alpine AS production
LABEL org.opencontainers.image.title="React Frontend"
COPY nginx.conf /etc/nginx/conf.d/default.conf
COPY --from=builder /app/build /usr/share/nginx/html
EXPOSE 8080
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD wget -q --spider http://localhost:8080/ || exit 1
CMD ["nginx", "-g", "daemon off;"]
```

#### Understanding the Frontend Dockerfile

Frontend applications present a unique case: the final container needs neither Node.js nor npm, only a web server to deliver static files.

**Build-Time Configuration**: The `ARG` instruction accepts `REACT_APP_API_URL` at build time, embedded into the static bundle during compilation. Different environments require separate image builds with different `ARG` values.

**nginx-unprivileged**: A hardened Nginx image that runs as a non-root user by default, listening on port 8080 rather than privileged port 80.

**nginx.conf**: Typically configures gzip compression, cache headers for static assets, and routing rules for single-page applications.

---

## 6. Advanced Dockerfile Patterns

### 6.1 Advanced Multi-Stage Build with Build Cache

```dockerfile
# syntax=docker/dockerfile:1.4

ARG NODE_VERSION=20
ARG ALPINE_VERSION=3.19

FROM node:${NODE_VERSION}-alpine${ALPINE_VERSION} AS base
RUN apk add --no-cache libc6-compat
WORKDIR /app

FROM base AS deps
COPY package.json package-lock.json ./
RUN --mount=type=cache,target=/root/.npm \
    npm ci --prefer-offline

FROM base AS dev-deps
COPY package.json package-lock.json ./
RUN --mount=type=cache,target=/root/.npm \
    npm ci --include=dev --prefer-offline

FROM base AS builder
COPY --from=dev-deps /app/node_modules ./node_modules
COPY . .
RUN --mount=type=cache,target=/app/.next/cache \
    npm run build

FROM base AS test
COPY --from=dev-deps /app/node_modules ./node_modules
COPY . .
RUN npm run lint && npm run test:ci

FROM base AS production
ENV NODE_ENV=production
RUN addgroup --system nodejs && adduser --system --ingroup nodejs nextjs
COPY --from=builder --chown=nextjs:nodejs /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static
USER nextjs
EXPOSE 3000
ENV PORT=3000 HOSTNAME="0.0.0.0"
CMD ["node", "server.js"]
```

#### Deep Dive: Advanced Multi-Stage Architecture

**Parameterized Base Images**: `ARG` instructions before any `FROM` allow base image versions to be specified at build time, enabling a single Dockerfile to target different Node.js versions.

**Shared Base Stage**: The `base` stage establishes common foundations. Installing `libc6-compat` addresses compatibility issues with certain npm packages on Alpine.

**Cache Mounts**: The `--mount=type=cache` directive instructs BuildKit to persist specified directories across builds. The npm cache and Next.js build cache survive between builds, dramatically reducing build times.

**Parallel Build Stages**: `deps` and `dev-deps` are independent branches from `base`. BuildKit executes these in parallel when possible.

**Next.js Standalone Output**: Modern Next.js supports standalone output mode, bundling only necessary files for production‚Äîreducing final image size by 60-80%.

---

### 6.2 Security-Hardened Dockerfile with Distroless

```dockerfile
FROM golang:1.22-alpine AS builder
RUN apk add --no-cache git ca-certificates tzdata
WORKDIR /build
COPY go.mod go.sum ./
RUN go mod download && go mod verify
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build \
    -ldflags='-w -s -extldflags "-static"' \
    -tags netgo \
    -o /app/server ./cmd/server

FROM gcr.io/distroless/static-debian12:nonroot AS production
COPY --from=builder /usr/share/zoneinfo /usr/share/zoneinfo
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/
COPY --from=builder /app/server /server
ENV TZ=UTC
EXPOSE 8080
USER nonroot:nonroot
ENTRYPOINT ["/server"]
```

#### Deep Dive: Distroless Security Architecture

**Google's Distroless Images**: Contain only the application and runtime dependencies‚Äîno shell, no package manager, no OS utilities. An attacker who gains code execution finds almost nothing to exploit.

**Static Binary Compilation**: Go build flags disable CGO, target Linux AMD64, and use linker flags to strip debug information (`-w -s`) and force static linking. The resulting binary has zero external dependencies.

**Essential File Copying**: Distroless images lack timezone data and CA certificates. We explicitly copy these from the builder stage for HTTPS connectivity and proper time handling.

**Nonroot Variant**: The `:nonroot` tag selects a distroless variant running as UID 65532 by default. With no shell or userspace utilities, there's no way to escalate privileges.

**Attack Surface Reduction**: Traditional images might have hundreds of CVEs in unused packages. Distroless images typically report zero or near-zero CVEs.

---

### 6.3 Monorepo Multi-Service Dockerfile

```dockerfile
# syntax=docker/dockerfile:1.4

FROM node:20-alpine AS base
RUN npm install -g turbo
WORKDIR /app

FROM base AS pruner
COPY . .
RUN turbo prune --scope=@acme/api --docker

FROM base AS installer
COPY --from=pruner /app/out/json/ .
COPY --from=pruner /app/out/package-lock.json ./package-lock.json
RUN --mount=type=cache,target=/root/.npm \
    npm ci
COPY --from=pruner /app/out/full/ .
RUN turbo run build --filter=@acme/api

FROM base AS api-runner
ENV NODE_ENV=production
RUN addgroup --system nodejs && adduser --system --ingroup nodejs api
COPY --from=installer --chown=api:nodejs /app/apps/api/dist ./dist
COPY --from=installer --chown=api:nodejs /app/apps/api/package.json ./
COPY --from=installer --chown=api:nodejs /app/node_modules ./node_modules
USER api
EXPOSE 3001
CMD ["node", "dist/main.js"]

FROM base AS web-pruner
COPY . .
RUN turbo prune --scope=@acme/web --docker

FROM base AS web-installer
COPY --from=web-pruner /app/out/json/ .
COPY --from=web-pruner /app/out/package-lock.json ./package-lock.json
RUN --mount=type=cache,target=/root/.npm npm ci
COPY --from=web-pruner /app/out/full/ .
ARG NEXT_PUBLIC_API_URL
ENV NEXT_PUBLIC_API_URL=$NEXT_PUBLIC_API_URL
RUN turbo run build --filter=@acme/web

FROM nginxinc/nginx-unprivileged:1.25-alpine AS web-runner
COPY --from=web-installer /app/apps/web/out /usr/share/nginx/html
EXPOSE 8080
CMD ["nginx", "-g", "daemon off;"]
```

#### Deep Dive: Monorepo Build Strategy

**Turbo Prune**: Analyzes the dependency graph and extracts only packages required for a specific scope. The `--docker` flag outputs in Docker-optimized format: `/out/json` for dependency installation, `/out/full` for complete source.

**Parallel Service Pipelines**: Separate build pipelines for API and web services. BuildKit executes independent stages in parallel.

**Target Selection**: `docker build --target api-runner` builds only the API, skipping the web pipeline. Integrates naturally with CI/CD systems detecting changed services.

**Shared Package Handling**: Turbo's prune automatically includes transitive dependencies, ensuring shared packages are present when needed.

---

### 6.4 CI/CD Optimized Dockerfile with Testing

```dockerfile
# syntax=docker/dockerfile:1.4

ARG PYTHON_VERSION=3.12

FROM python:${PYTHON_VERSION}-slim AS base
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

FROM base AS builder
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential libpq-dev && rm -rf /var/lib/apt/lists/*
WORKDIR /app
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
COPY requirements/base.txt requirements/base.txt
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -r requirements/base.txt

FROM builder AS dev-builder
COPY requirements/dev.txt requirements/dev.txt
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -r requirements/dev.txt

FROM dev-builder AS lint
COPY . .
RUN ruff check . && ruff format --check .

FROM dev-builder AS typecheck
COPY . .
RUN mypy src --strict

FROM dev-builder AS test
COPY . .
RUN pytest tests/ -v --cov=src --cov-report=xml

FROM dev-builder AS security-scan
COPY . .
RUN bandit -r src/ && safety check

FROM base AS production
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq5 && rm -rf /var/lib/apt/lists/*
RUN groupadd --system app && useradd --system --gid app app
WORKDIR /app
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
COPY --chown=app:app src/ ./src/
USER app
EXPOSE 8000
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"
CMD ["gunicorn", "src.main:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "-b", "0.0.0.0:8000"]
```

#### Deep Dive: CI/CD Integration Patterns

**Verification Stage Pattern**: Each `FROM...AS` creates an independently buildable target. In CI, run `docker build --target lint` in one job, `--target test` in another. Failed jobs pinpoint exactly what broke.

**Dependency Layering**: Requirements split into `base.txt` (production) and `dev.txt` (testing/linting). Production stage copies only from builder, ensuring no dev tools leak into the final image.

**Security Scanning**: Bandit (static analysis) and Safety (vulnerability database checks) run in Docker for consistent tool versions across environments.

**CI Configuration Example**:
```yaml
jobs:
  lint:
    run: docker build --target lint .
  test:
    run: docker build --target test .
  security:
    run: docker build --target security-scan .
  build:
    needs: [lint, test, security]
    run: docker build --target production -t app:latest .
```

---

## 7. Best Practices Summary

### 7.1 Image Optimization

| Practice | Benefit |
|----------|---------|
| Use multi-stage builds | Reduce final image size by 50-90% |
| Choose minimal base images (Alpine, slim, distroless) | Smaller attack surface, faster pulls |
| Order layers by change frequency | Maximize cache utilization |
| Clean up in the same layer | Avoid bloating image with temp files |

### 7.2 Security Hardening

| Practice | Benefit |
|----------|---------|
| Run as non-root user | Limit container compromise impact |
| Use specific image tags | Ensure reproducible builds |
| Scan images for vulnerabilities | Catch CVEs before deployment |
| Don't store secrets in images | Prevent credential exposure |

### 7.3 Build Efficiency

| Practice | Benefit |
|----------|---------|
| Use .dockerignore files | Reduce build context size |
| Leverage BuildKit | Enable parallel builds, cache mounts |
| Use COPY instead of ADD | Predictable behavior |
| Enable cache mounts | Speed up dependency installation |

### 7.4 Production Readiness

| Practice | Benefit |
|----------|---------|
| Include health checks | Enable automatic recovery |
| Handle signals properly (dumb-init, tini) | Graceful shutdown |
| Write logs to stdout/stderr | Proper log aggregation |
| Configure resource awareness | Prevent OOM kills |

---

## üìö Additional Resources

- [Docker Documentation](https://docs.docker.com/)
- [Dockerfile Best Practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)
- [BuildKit Documentation](https://docs.docker.com/build/buildkit/)
- [Distroless Images](https://github.com/GoogleContainerTools/distroless)
- [OCI Image Specification](https://github.com/opencontainers/image-spec)

---

## üìÑ License

This guide is provided for educational purposes. Feel free to use and adapt these Dockerfiles for your projects.

---

<p align="center">
  <i>Happy Containerizing! üê≥</i>
</p>
